
### 9.1 图像增广
前提：需要通过⼤规模数据集使深度神经⽹络成功应⽤
图像增⼴（image augmentation）：为了扩⼤训练数据集的规模，通过对训练图像的⼀系列随机改变，产⽣相似但⼜不同的训练样本。
另一种解释：通过随机改变训练样本，使模型降低对某些属性的依赖。提⾼林模型的泛化能⼒（generalization ability）。
手段包括：剪裁、移动。调整亮度、色彩等。

### 9.2 迁移学习（transfer learning）
通过模型对数据集进行训练，抽取[边缘、纹理、形状和物体组成等]通⽤的图像特征进行分析，提高模型精度，减少对单一种类的过拟合，降低数据采集成本。
迁移学习中的常用技术：微调（fine tuning）。
1. 在源数据集（如ImageNet数据集）上预训练⼀个神经⽹络模型，即源模型。
2. 创建⼀个新的神经⽹络模型，即⽬标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适⽤于⽬标数据集。我们还假设源模型的输出层与源数据集的标签紧密相关，因此在⽬标模 型中不予采⽤。
3. 为⽬标模型添加⼀个输出⼤小为⽬标数据集类别个数的输出层，并随机初始化该层的模型参数。
4. 在⽬标数据集（如椅⼦数据集）上训练⽬标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。

### 9.3-1 选择性搜索[^ss]算法
图像分割是计算机视觉领域很重要的一项任务。选择性搜索算法，应用于图像分割领域。也是目标识别领域的基础。

图像分割、目标识别选择以深度学习来实现的一部分原因：这样可以省去人工特征的构造和分类算法的设计，提升泛化能力。

ss算法主要用于解决目标识别领域中，输入分类器候选区域的选择问题。
ss算法并不是表达每个物体的精确位置，而是提供多个候选区域。在候选区域中有很小一部分会和我们想要的窗口大小和位置很接近。后续再通过其他手段[^其他手段] 来去除冗余的一些窗口。

参考原文《Efficient Graph-Based Image Segmentation》

基本思想：先对图像进行分割(尽量打碎)，[使用基于图论的图像分割方法]分成尽可能多的不重复的子区域（$A=R_{1} \cup R_{2} \cup \ldots \cup R_{n}$）。接下来算法根据子区域的大小,尺寸,颜色或纹理等方法计算相邻子区域的相似度，依次往复直到求出所有的相似度 $s_{ij}$ ，构成集合 $S$。

随后需找出 $S$ 集合中值最大的元素[相似度最高的两个子区域]。
$$ i, j=\arg \max_{ij} \left(S_{i, j}\right)$$

若 $\max(S) = S_{1,2}$ 则
1. 合并子区域 $R_1$，$R_2$ 为新的子区域 $R_{n+1}$，并入集合 $A$ 中。$A=A \cup R_{n+1}$
2. 在集合 $S$ 中删除合并前与**子区域**所有相关的相似度。$S=S/ S_{1, *}, S=S/S_{2, *}$
3. 重复以上操作，直至 $S$ 为空集。

$$\begin{array}{c}
S=\emptyset \\
A=R_{1} \cup R_{2} \cup \ldots \cup R_{n+1} \cup \ldots \cup R_{n+m}
\end{array}$$

此时 $A$ 集合中多出了 $n+m$ 个元素，这些元素是由原先不同的相邻的子区域组合而成的。这个算法给出的候选区域的数量是可以通过参数进行调节的。

我们将这些候选区域称为 Region Proposals。

[^ss]: Selective Search
[^其他手段]: 非极大值抑制

### 9.3 ⽬标检测
图像分类任务中，只有一个主体目标图像里，主要关注该目标的类别。
目标检测(object detection)或物体检测则是针对图像中多个感兴趣的目标，分辨目标类别(事先制指定好的)和图中的具体位置。
在无人驾驶、安防、医疗等领域中有着普遍应用。
目标检测有很长的历史：(本例只展示基于深度学习的目标识别算法)：
2014(R-CNN, SPP-Net) -> 2015(Fast R-CNN, Faster R-CNN) -> 2016(SSD, YOLO)
以下会列出⽬标检测问题⾥的多个深度学习模型。

#### 9.3.1 边界框
目标检测问题，通常使用[矩形的]边界框(bounding box)标定目标位置。
边界框可以由矩形左上角的坐标 $(x_1,y_1)$ 及其右下角的坐标 $(x_4, y_4)$ 确定。

### 9.4 锚框
以每个像素为中⼼⽣成多个⼤小和宽⾼⽐（aspect ratio）不同的边界框。这些边界框被称为锚框（anchor box）。
#### 9.4.1 ⽣成多个锚框

#### 9.4.2 交并⽐
Jaccard系数[^IoU]：⼆者交集⼤小除以⼆者并集
$$J(\mathcal{A}, \mathcal{B})=\frac{|\mathcal{A} \cap \mathcal{B}|}{|\mathcal{A} \cup \mathcal{B}|}$$
[^IoU]: 当衡量两个边界框的相似度时，通常称为交并⽐（intersection over union，IoU）
### 9.8 R-CNN
#### 9.8.1 R-CNN[^R-CNN]
R-CNN: 区域卷积神经⽹络（Region-based CNN or Regions with CNN features）
1. 获得 `INPUT IMAGE` 
2. 将其拆解为两千张候选的区域（Extract region proposals）使用 `selective search` 算法
3. 将每一张 region proposal 输入一个神经网路 (e.g. CNN)
4. 全连接层会输出[^OUTPUT]对应的特征向量，将其输入到多个线性二分类器(e.g. SVM)中，来判断类别。
5. 使用回归网络修正 region proposal 位置。
6. 通过非极大值抑制[^NMS]得到最终很精确的每一个物体的位置。

权重初始化问题
（目的：使参数更快收敛到极小值点）使用 微调(Fine Tune) 

R-CNN与简单图像分类一样需要很多训练样本，区别为前者中每一个训练样本都需要进行标注处理。标注处理过的 bounding box 称作 基准真相（Ground Truth），或者理解为基准 bounding box。

训练目的：对于新的输入，R-CNN 可以将图中的每一个物体以 Ground Truth 的精度标注出来。

对于未收敛于GT的 region proposal 在分类时，应计算IOU：
$$\text {label}=\left\{\begin{array}{cl}
\text {dog} & \text {IOU}>50 \% \\
\text {background} & \text {IOU} \leq 50 \%
\end{array}\right.$$

设 region proposal 位置：$P=\left(P_{x}, P_{y}, P_{w}, P_{h}\right)$
Ground Truth 的位置：$G=\left(G_{x}, G_{y}, G_{w}, G_{h}\right)$

回归网络的训练目标是学习一个 P->G 的映射

$$\begin{aligned}
&\hat{G}_{x}=P_{w} d_{x}(P)+P_{x}\\
&\hat{G}_{y}=P_{h} d_{y}(P)+P_{y}\\
&\hat{G}_{w}=P_{w} e^{d_{w}(P)}\\
&\hat{G}_{h}=P_{w} e^{d_{h}(P)}
\end{aligned}$$

$$d_{*}(P)=w_{*}^{T} \phi_{5}(P)$$

其中 $d_{x}(P)$, $d_{y}(P)$, $d_{w}(P)$, $d_{h}(P)$ 是四个线性函数，输入为 $P$（即NN第五层输出的特征向量），输出为一个实数。
训练本质是求解一个最优化问题。
$$w_{*}=\arg \min _{\hat{w}_{*}} \sum_{i}^{N}\left(t_{*}^{i}-\hat{w}_{*}^{T} \phi_{5}\left(P^{i}\right)\right)^{2}+\lambda\left\|\hat{w}_{*}\right\|^{2}$$
求出四个 $w$ 向量，使得预测值 $G$ 和真实值 $G$ 相差最小。用差平方之和代表距离。同时为了抑制过拟合增加了正则项。
$$\begin{aligned}
&t_{x}=\frac{\left(G_{x}-P_{x}\right)}{P_{w}}\\
&t_{y}=\frac{\left(G_{y}-P_{y}\right)}{P_{h}}\\
&t_{w}=\log \left(\frac{G_{w}}{P_{w}}\right)\\
&t_{h}=\log \left(\frac{G_{h}}{P_{h}}\right)
\end{aligned}$$
训练完成后就会得到对应的四个映射关系，测试时这四个映射关系就能够对预测的 Region Proposal 进行相应的位置调整。提升 bounding box 位置精确度。

最后通过位置回归修正 bounding box 的位置之后，对于同一个物体会得到多个 bounding box。对这些 bounding box 本别打分，通过非极大值抑制去除冗余 bounding box。

非极大值抑制可以理解为：在相邻的 bounding box 中去除分数不是极大值的 bounding box。这里的分数也可叫做置信度。也就网络对于自己预测的结果到底有多少信心。

SVM正负样本的定义和神经网络正负样本定义不是很一样。
正样本是 Ground Truth；负样本是和 Ground Truth 重合率小于 30% 的 Region Proposal。
使用SVM来代替CNN做分类的原因:CNN本身挑选出来的正样本中存在很多位置不精确的 Bounding Box。导致最后物体识别的 Bounding Box 位置也不是很准确。

原论文同时使用了 Hard Mining。可以简单理解为将负样本中那些容易和正样本混淆的样本单独拿出来训练。

引用来源：
https://handong1587.github.io/study/2017/11/28/courses.html

[^R-CNN]: 引用来源：2020海华AI挑战赛·垃圾识别 目标识别与R-CNN概述
[^OUTPUT]: 输出层为指定的目标类别，另包括背景类。
[^NMS]: NMS(Non Maximum Suppression)：是一种去除非极大值的算法，常用于计算机视觉中的边缘检测、物体识别等。


#### 9.8.2 Fast R-CNN
#### 9.8.3 Faster R-CNN
#### 9.8.4 Mask R-CNN

### 9.9 语义分割和数据集

### 9.10 全卷积⽹络（FCN）
全卷积⽹络（fully convolutional network，FCN）采⽤卷积神经⽹络实现了从图像像素到像素类别的变换。
与卷积神经网络不同：
卷积神经⽹络通过转置卷积（transposed convolution）层将中间层特征图的⾼和宽变换回输⼊图像的尺⼨，[预测结果]与[输⼊图像]在空间维(⾼和宽)保持一致。
给定空间维上的位置，通道维的输出即该位置对应像素的类别预测。

#### 9.10.1 转置卷积层