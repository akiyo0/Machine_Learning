{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0da1f610aa45a19559334a3d75bd9f7f779eed9e987951440e2e8e0c4216a7c30",
   "display_name": "Python 3.8.5 64-bit ('tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## ch02-01"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### EMSE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5531726674375732\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = [1.0, 1.5, 2.0, 1.2, 1.8]\n",
    "y_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "source": [
    "### RMSLE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Confusion Matrix 混同行列"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[3 1]\n [2 2]]\n[[2 1]\n [2 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "tp = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 1))\n",
    "tn = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 0))\n",
    "fp = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 1))\n",
    "fn = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 0))\n",
    "\n",
    "cm_1 = np.array([[tp, fp], [fn, tn]])\n",
    "#TP, FP, FN, TN\n",
    "print(cm_1)\n",
    "\n",
    "cm_2 = confusion_matrix(y_true, y_pred)\n",
    "#TN, FP, FN, TP\n",
    "print(cm_2)"
   ]
  },
  {
   "source": [
    "### Accurary 正答率, Error Rate 誤答率\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "source": [
    "### logloss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7135581778200728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "y_true = [1, 0, 1, 1, 0, 1]\n",
    "y_pred = [0.1, 0.2, 0.8, 0.8, 0.1, 0.3]\n",
    "\n",
    "logloss = log_loss(y_true, y_pred)\n",
    "print(logloss)"
   ]
  },
  {
   "source": [
    "### MAP@K"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6499999999999999\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "\n",
    "y_true = [[1, 2], [1, 2], [4], [1, 2, 3, 4], [3, 4]]\n",
    "y_pred = [[1, 2, 4], [4, 1, 2], [1, 4, 3], [1, 2, 3], [1, 2, 4]]\n",
    "\n",
    "def apk(y_true, y_pred):\n",
    "    assert(len(y_pred) <= K)\n",
    "    assert(len(np.unique(y_pred)) == len(y_pred))\n",
    "\n",
    "    sum_precision = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(y_pred):\n",
    "        if p in y_true:\n",
    "            num_hits += 1\n",
    "            precision = num_hits/(i+1)\n",
    "            sum_precision += precision\n",
    "    \n",
    "    return sum_precision / min(len(y_true), K)\n",
    "\n",
    "def mapk(Y_true, Y_pred):\n",
    "    return np.mean([apk(y_true, y_pred) for y_true, y_pred in zip(Y_true, Y_pred)])\n",
    "\n",
    "print(mapk(y_true, y_pred))"
   ]
  },
  {
   "source": [
    "## ch02-02"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### XGBoostにおけるカスタム評価指標とカスタム目的関数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train = pd.read_csv('../dataset/insurance/train_preprocessed.csv')\n",
    "x_train_total = train.drop(['target'], axis=1)\n",
    "y_train_total = train['target']\n",
    "x_test_total = pd.read_csv('../dataset/insurance/test_preprocessed.csv')\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "train_idx, val_idx = list(kf.split(x_train_total))[0]\n",
    "x_train, x_val = x_train_total.iloc[train_idx], x_train_total.iloc[val_idx]\n",
    "y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\ttrain-logloss:0.54088\teval-logloss:0.55003\n",
      "[1]\ttrain-logloss:0.45269\teval-logloss:0.47182\n",
      "[2]\ttrain-logloss:0.39482\teval-logloss:0.42026\n",
      "[3]\ttrain-logloss:0.35198\teval-logloss:0.38520\n",
      "[4]\ttrain-logloss:0.32021\teval-logloss:0.36150\n",
      "[5]\ttrain-logloss:0.29673\teval-logloss:0.34463\n",
      "[6]\ttrain-logloss:0.27610\teval-logloss:0.32900\n",
      "[7]\ttrain-logloss:0.25886\teval-logloss:0.31670\n",
      "[8]\ttrain-logloss:0.24363\teval-logloss:0.30775\n",
      "[9]\ttrain-logloss:0.23153\teval-logloss:0.30092\n",
      "[10]\ttrain-logloss:0.22016\teval-logloss:0.29413\n",
      "[11]\ttrain-logloss:0.20963\teval-logloss:0.28528\n",
      "[12]\ttrain-logloss:0.19951\teval-logloss:0.27912\n",
      "[13]\ttrain-logloss:0.19324\teval-logloss:0.27642\n",
      "[14]\ttrain-logloss:0.18547\teval-logloss:0.27154\n",
      "[15]\ttrain-logloss:0.17474\teval-logloss:0.26516\n",
      "[16]\ttrain-logloss:0.16900\teval-logloss:0.26089\n",
      "[17]\ttrain-logloss:0.16323\teval-logloss:0.25849\n",
      "[18]\ttrain-logloss:0.15950\teval-logloss:0.25691\n",
      "[19]\ttrain-logloss:0.15637\teval-logloss:0.25511\n",
      "[20]\ttrain-logloss:0.14722\teval-logloss:0.25034\n",
      "[21]\ttrain-logloss:0.14290\teval-logloss:0.24734\n",
      "[22]\ttrain-logloss:0.13782\teval-logloss:0.24612\n",
      "[23]\ttrain-logloss:0.13362\teval-logloss:0.24387\n",
      "[24]\ttrain-logloss:0.13047\teval-logloss:0.24251\n",
      "[25]\ttrain-logloss:0.12654\teval-logloss:0.24094\n",
      "[26]\ttrain-logloss:0.12268\teval-logloss:0.24005\n",
      "[27]\ttrain-logloss:0.11966\teval-logloss:0.23803\n",
      "[28]\ttrain-logloss:0.11506\teval-logloss:0.23699\n",
      "[29]\ttrain-logloss:0.11027\teval-logloss:0.23626\n",
      "[30]\ttrain-logloss:0.10827\teval-logloss:0.23621\n",
      "[31]\ttrain-logloss:0.10262\teval-logloss:0.23269\n",
      "[32]\ttrain-logloss:0.10061\teval-logloss:0.23212\n",
      "[33]\ttrain-logloss:0.09913\teval-logloss:0.23180\n",
      "[34]\ttrain-logloss:0.09582\teval-logloss:0.23184\n",
      "[35]\ttrain-logloss:0.09378\teval-logloss:0.22998\n",
      "[36]\ttrain-logloss:0.09243\teval-logloss:0.22980\n",
      "[37]\ttrain-logloss:0.08952\teval-logloss:0.22913\n",
      "[38]\ttrain-logloss:0.08732\teval-logloss:0.22870\n",
      "[39]\ttrain-logloss:0.08576\teval-logloss:0.22786\n",
      "[40]\ttrain-logloss:0.08340\teval-logloss:0.22857\n",
      "[41]\ttrain-logloss:0.08125\teval-logloss:0.22695\n",
      "[42]\ttrain-logloss:0.08027\teval-logloss:0.22645\n",
      "[43]\ttrain-logloss:0.07829\teval-logloss:0.22659\n",
      "[44]\ttrain-logloss:0.07616\teval-logloss:0.22607\n",
      "[45]\ttrain-logloss:0.07522\teval-logloss:0.22499\n",
      "[46]\ttrain-logloss:0.07313\teval-logloss:0.22316\n",
      "[47]\ttrain-logloss:0.07198\teval-logloss:0.22293\n",
      "[48]\ttrain-logloss:0.07025\teval-logloss:0.22265\n",
      "[49]\ttrain-logloss:0.06947\teval-logloss:0.22226\n",
      "0.22226432168299798\n",
      "[0]\ttrain-rmse:0.40042\ttrain-custom-error:0.16947\teval-rmse:0.42362\teval-custom-error:0.19080\n",
      "[1]\ttrain-rmse:0.70228\ttrain-custom-error:0.11547\teval-rmse:0.72145\teval-custom-error:0.14920\n",
      "[2]\ttrain-rmse:0.98133\ttrain-custom-error:0.10280\teval-rmse:0.99697\teval-custom-error:0.13520\n",
      "[3]\ttrain-rmse:1.22320\ttrain-custom-error:0.09920\teval-rmse:1.23609\teval-custom-error:0.13680\n",
      "[4]\ttrain-rmse:1.43865\ttrain-custom-error:0.09453\teval-rmse:1.44949\teval-custom-error:0.13720\n",
      "[5]\ttrain-rmse:1.63033\ttrain-custom-error:0.08947\teval-rmse:1.63831\teval-custom-error:0.12920\n",
      "[6]\ttrain-rmse:1.79480\ttrain-custom-error:0.08453\teval-rmse:1.80122\teval-custom-error:0.12920\n",
      "[7]\ttrain-rmse:1.94509\ttrain-custom-error:0.07920\teval-rmse:1.94581\teval-custom-error:0.12640\n",
      "[8]\ttrain-rmse:2.06040\ttrain-custom-error:0.07680\teval-rmse:2.06055\teval-custom-error:0.12840\n",
      "[9]\ttrain-rmse:2.16885\ttrain-custom-error:0.07160\teval-rmse:2.16838\teval-custom-error:0.12400\n",
      "[10]\ttrain-rmse:2.27799\ttrain-custom-error:0.06853\teval-rmse:2.27434\teval-custom-error:0.12320\n",
      "[11]\ttrain-rmse:2.37375\ttrain-custom-error:0.06347\teval-rmse:2.36658\teval-custom-error:0.11640\n",
      "[12]\ttrain-rmse:2.45789\ttrain-custom-error:0.06200\teval-rmse:2.44850\teval-custom-error:0.11640\n",
      "[13]\ttrain-rmse:2.54263\ttrain-custom-error:0.05640\teval-rmse:2.52881\teval-custom-error:0.11480\n",
      "[14]\ttrain-rmse:2.63597\ttrain-custom-error:0.05307\teval-rmse:2.62313\teval-custom-error:0.11160\n",
      "[15]\ttrain-rmse:2.69488\ttrain-custom-error:0.04973\teval-rmse:2.67976\teval-custom-error:0.11120\n",
      "[16]\ttrain-rmse:2.75300\ttrain-custom-error:0.04773\teval-rmse:2.73074\teval-custom-error:0.11280\n",
      "[17]\ttrain-rmse:2.81005\ttrain-custom-error:0.04613\teval-rmse:2.78479\teval-custom-error:0.11320\n",
      "[18]\ttrain-rmse:2.87602\ttrain-custom-error:0.04280\teval-rmse:2.84483\teval-custom-error:0.11040\n",
      "[19]\ttrain-rmse:2.93112\ttrain-custom-error:0.04187\teval-rmse:2.89821\teval-custom-error:0.10800\n",
      "[20]\ttrain-rmse:2.98633\ttrain-custom-error:0.03853\teval-rmse:2.95071\teval-custom-error:0.10600\n",
      "[21]\ttrain-rmse:3.03141\ttrain-custom-error:0.03747\teval-rmse:2.99213\teval-custom-error:0.10520\n",
      "[22]\ttrain-rmse:3.08452\ttrain-custom-error:0.03573\teval-rmse:3.04040\teval-custom-error:0.10320\n",
      "[23]\ttrain-rmse:3.14076\ttrain-custom-error:0.03213\teval-rmse:3.09457\teval-custom-error:0.10000\n",
      "[24]\ttrain-rmse:3.19359\ttrain-custom-error:0.03160\teval-rmse:3.14409\teval-custom-error:0.10160\n",
      "[25]\ttrain-rmse:3.22294\ttrain-custom-error:0.03160\teval-rmse:3.17373\teval-custom-error:0.10200\n",
      "[26]\ttrain-rmse:3.25593\ttrain-custom-error:0.02920\teval-rmse:3.20251\teval-custom-error:0.10160\n",
      "[27]\ttrain-rmse:3.31172\ttrain-custom-error:0.02560\teval-rmse:3.25334\teval-custom-error:0.09880\n",
      "[28]\ttrain-rmse:3.36408\ttrain-custom-error:0.02467\teval-rmse:3.30130\teval-custom-error:0.09760\n",
      "[29]\ttrain-rmse:3.42476\ttrain-custom-error:0.02413\teval-rmse:3.36154\teval-custom-error:0.09920\n",
      "[30]\ttrain-rmse:3.46233\ttrain-custom-error:0.02080\teval-rmse:3.39506\teval-custom-error:0.09720\n",
      "[31]\ttrain-rmse:3.52163\ttrain-custom-error:0.01960\teval-rmse:3.44925\teval-custom-error:0.09600\n",
      "[32]\ttrain-rmse:3.56559\ttrain-custom-error:0.01947\teval-rmse:3.48924\teval-custom-error:0.09600\n",
      "[33]\ttrain-rmse:3.60194\ttrain-custom-error:0.01880\teval-rmse:3.52528\teval-custom-error:0.09800\n",
      "[34]\ttrain-rmse:3.63756\ttrain-custom-error:0.01840\teval-rmse:3.55930\teval-custom-error:0.09960\n",
      "[35]\ttrain-rmse:3.68200\ttrain-custom-error:0.01667\teval-rmse:3.60190\teval-custom-error:0.09720\n",
      "[36]\ttrain-rmse:3.71468\ttrain-custom-error:0.01587\teval-rmse:3.63565\teval-custom-error:0.09480\n",
      "[37]\ttrain-rmse:3.76866\ttrain-custom-error:0.01467\teval-rmse:3.68550\teval-custom-error:0.09600\n",
      "[38]\ttrain-rmse:3.79198\ttrain-custom-error:0.01413\teval-rmse:3.70616\teval-custom-error:0.09600\n",
      "[39]\ttrain-rmse:3.81722\ttrain-custom-error:0.01333\teval-rmse:3.73048\teval-custom-error:0.09720\n",
      "[40]\ttrain-rmse:3.85869\ttrain-custom-error:0.01187\teval-rmse:3.76862\teval-custom-error:0.09920\n",
      "[41]\ttrain-rmse:3.88978\ttrain-custom-error:0.01173\teval-rmse:3.79850\teval-custom-error:0.09720\n",
      "[42]\ttrain-rmse:3.92152\ttrain-custom-error:0.01133\teval-rmse:3.82730\teval-custom-error:0.09840\n",
      "[43]\ttrain-rmse:3.96269\ttrain-custom-error:0.01027\teval-rmse:3.86508\teval-custom-error:0.09840\n",
      "[44]\ttrain-rmse:3.99083\ttrain-custom-error:0.01080\teval-rmse:3.89179\teval-custom-error:0.09720\n",
      "[45]\ttrain-rmse:4.02467\ttrain-custom-error:0.00987\teval-rmse:3.91969\teval-custom-error:0.09720\n",
      "[46]\ttrain-rmse:4.06247\ttrain-custom-error:0.00853\teval-rmse:3.95514\teval-custom-error:0.09840\n",
      "[47]\ttrain-rmse:4.10605\ttrain-custom-error:0.00773\teval-rmse:3.99457\teval-custom-error:0.09840\n",
      "[48]\ttrain-rmse:4.12540\ttrain-custom-error:0.00733\teval-rmse:4.01296\teval-custom-error:0.09760\n",
      "[49]\ttrain-rmse:4.14995\ttrain-custom-error:0.00733\teval-rmse:4.03671\teval-custom-error:0.10040\n",
      "0.22561102085065796\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "dtrain = xgboost.DMatrix(x_train, label=y_train)\n",
    "dvalid = xgboost.DMatrix(x_val, label=y_val)\n",
    "\n",
    "def logregobj(y_preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    y_preds = 1.0 / (1.0 + np.exp(-y_preds))\n",
    "    grad = y_preds - y_true\n",
    "    hess = y_preds * (1.0 - y_preds) #二階微分値\n",
    "    return grad, hess\n",
    "\n",
    "def evalerror(y_preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    return 'custom-error', float(sum(y_true != (y_preds > 0.0))) / len(y_true)\n",
    "\n",
    "num_round = 50\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "# Method1 (usual)\n",
    "params = {'random_state': 71, 'objective': 'binary:logistic', 'eval_metric': 'logloss'}\n",
    "bst = xgboost.train(params, dtrain, num_round, watchlist)\n",
    "\n",
    "y_pred = bst.predict(dvalid)\n",
    "logloss = log_loss(y_val, y_pred)\n",
    "print(logloss)\n",
    "\n",
    "# Method2\n",
    "params = {'random_state': 71} # 'silent': 1, \n",
    "bst = xgboost.train(params, dtrain, num_round, watchlist, obj=logregobj, feval=evalerror)\n",
    "\n",
    "y_pred = bst.predict(dvalid)\n",
    "y_pred = 1.0 / (1.0 + np.exp(-y_pred)) # 変換が必要\n",
    "logloss = log_loss(y_val, y_pred)\n",
    "print(logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}